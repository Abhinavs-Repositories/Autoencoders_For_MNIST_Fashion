# TensorFlow 2.x Stacked Autoencoder

Explore the capabilities of Autoencoders and dimensionality reduction with this TensorFlow 2.x implementation of a Stacked Autoencoder trained on the Fashion MNIST dataset.

## Features:

- **Stacked Autoencoder Architecture:**
  - Utilizes a stacked architecture comprising encoder and decoder layers for effective feature extraction and image reconstruction.

- **Binary Crossentropy Loss:**
  - The model is trained using binary crossentropy loss and is optimized using Stochastic Gradient Descent (SGD).

- **Dimensionality Reduction:**
  - Applies t-SNE (t-distributed Stochastic Neighbor Embedding) for visualizing the compressed features in a 2D space.

- **Manifold Visualization:**
  - Demonstrates the manifold visualization of compressed features, highlighting patterns and relationships in the Fashion MNIST dataset.

## Usage:

1. **Clone the Repository:**
   - Clone this repository to your local machine using `git clone`.

2. **Open the Jupyter Notebook:**
   - Explore the Stacked Autoencoder implementation and its training process in the provided Jupyter Notebook.

3. **Run the Code:**
   - Execute the code cells to observe the training progress, reconstruction results, and dimensionality reduction visualization.

## Getting Started:

1. **Dependencies:**
   - Ensure you have the required dependencies installed, including TensorFlow, NumPy, Matplotlib, and Scikit-Learn.

2. **Run in a Jupyter Environment:**
   - Open the Jupyter Notebook in a compatible environment, such as Google Colab or Jupyter Notebook.

3. **Execute Code Cells:**
   - Run each code cell sequentially to observe the Stacked Autoencoder in action.

## Results:

- **Reconstruction Showcase:**
  - View reconstructed images generated by the Stacked Autoencoder on the test set.

- **Dimensionality Reduction Visualization:**
  - Explore the 2D visualization of compressed features using t-SNE, annotated with Fashion MNIST images.

Feel free to experiment with the code and explore different aspects of Autoencoders and dimensionality reduction!
